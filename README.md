# ğŸ– Real-Time ASL Alphabet Translator

## ğŸ“Œ Project Overview

This project is a real-time American Sign Language (ASL) Alphabet Translator that uses a webcam to recognize hand gestures and translate them into corresponding letters. It leverages MediaPipe Hands for hand tracking and TensorFlow for gesture classification.

## ğŸš€ Features

ğŸ–¥ï¸ Real-time hand tracking using OpenCV and MediaPipe

âœ‹ Detection of ASL letters (A-Z)

ğŸ¯ Accurate landmark detection with MediaPipe

ğŸ” Future expansion for full ASL words and sentences

## ğŸ› ï¸ Technologies Used

Python ğŸ

OpenCV ğŸ¥

MediaPipe Hands ğŸ–ï¸

TensorFlow ğŸ¤–

## ğŸ”§ Installation

### Clone this repository:

git clone https://github.com/your-username/ASL-Translator.git

cd ASL-Translator

### Install dependencies:

pip install opencv-python mediapipe tensorflow numpy fastapi uvicorn

### Run the application:

python main.py

# ğŸ“Œ Future Enhancements

âœ¨ Train a deep learning model for dynamic gesture recognition

ğŸŒ Expand to full ASL words and sentences

ğŸ“± Deploy as a web or mobile application

ğŸ¤ Contributing

Contributions are welcome! Feel free to submit pull requests or open issues.

ğŸ“œ License

This project is licensed under the MIT License.
