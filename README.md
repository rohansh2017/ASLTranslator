# 🖐 Real-Time ASL Alphabet Translator

## 📌 Project Overview

This project is a real-time American Sign Language (ASL) Alphabet Translator that uses a webcam to recognize hand gestures and translate them into corresponding letters. It leverages MediaPipe Hands for hand tracking and TensorFlow for gesture classification.

## 🚀 Features

🖥️ Real-time hand tracking using OpenCV and MediaPipe

✋ Detection of ASL letters (A-Z)

🎯 Accurate landmark detection with MediaPipe

🔍 Future expansion for full ASL words and sentences

## 🛠️ Technologies Used

Python 🐍

OpenCV 🎥

MediaPipe Hands 🖐️

TensorFlow 🤖

## 🔧 Installation

### Clone this repository:

git clone https://github.com/your-username/ASL-Translator.git

cd ASL-Translator

### Install dependencies:

pip install opencv-python mediapipe tensorflow numpy fastapi uvicorn

### Run the application:

python main.py

# 📌 Future Enhancements

✨ Train a deep learning model for dynamic gesture recognition

🌎 Expand to full ASL words and sentences

📱 Deploy as a web or mobile application

🤝 Contributing

Contributions are welcome! Feel free to submit pull requests or open issues.

📜 License

This project is licensed under the MIT License.
